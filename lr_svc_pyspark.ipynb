{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lr_svc_pyspark.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOkR5UraPqLD8E6mLvLVFnf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rashida048/ApacheSpark-BigDataAnalytics/blob/main/lr_svc_pyspark.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "isNXbEvl5Zo_",
        "outputId": "d52a78df-21ac-43a1-93ea-27014c224715"
      },
      "source": [
        "!pip install pyspark"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyspark\n",
            "  Downloading pyspark-3.1.2.tar.gz (212.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 212.4 MB 62 kB/s \n",
            "\u001b[?25hCollecting py4j==0.10.9\n",
            "  Downloading py4j-0.10.9-py2.py3-none-any.whl (198 kB)\n",
            "\u001b[K     |████████████████████████████████| 198 kB 53.9 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.1.2-py2.py3-none-any.whl size=212880768 sha256=922d4b85fccda5877aad77c6154cf7f5887d803d0a1ddd9900fe55935d1fd669\n",
            "  Stored in directory: /root/.cache/pip/wheels/a5/0a/c1/9561f6fecb759579a7d863dcd846daaa95f598744e71b02c77\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.9 pyspark-3.1.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6mXbkb5j5irQ"
      },
      "source": [
        "task3_total_strt = timeit.default_timer()\n",
        "from pyspark import SparkContext\n",
        "sc = SparkContext.getOrCreate()"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wy4LeL0d5uxg"
      },
      "source": [
        "from pyspark.sql.session import SparkSession\n",
        "spark = SparkSession.builder.getOrCreate()"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OL19tp3v5vPf"
      },
      "source": [
        "import re\n",
        "import numpy as np"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yyb4779a5wl5"
      },
      "source": [
        "def buildArray(listOfIndices):\n",
        "  returnVal = np.zeros(20000)\n",
        "\n",
        "  for index in listOfIndices:\n",
        "    returnVal[index] = returnVal[index] + 1\n",
        "\n",
        "  mysum = np.sum(returnVal)\n",
        "\n",
        "  returnVal = np.divide(returnVal, mysum)\n",
        "  return returnVal"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "prnex7Vf5yIR"
      },
      "source": [
        "def changeBinary(x):\n",
        "  if \"AU\" in x:\n",
        "    return 1\n",
        "  else:\n",
        "    return 0"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GOQote6e50oH"
      },
      "source": [
        "def conversion(rd):\n",
        "  validLines = rd.filter(lambda x: 'id' in x and 'url=' in x)\n",
        "  keyAndText = validLines.map(lambda x : (x[x.index('id=\"') + 4 : x.index('\" url=')], x[x.index('\">') + 2:][:-6]))\n",
        "  regex = re.compile('[^a-zA-Z]')\n",
        "  keyAndListOfWords = keyAndText.map(lambda x : (str(x[0]), regex.sub(' ', x[1]).lower().split()))\n",
        "  allWords = keyAndListOfWords.flatMap(lambda x: [(y, 1) for y in x[1]])\n",
        "  allCounts = allWords.reduceByKey(lambda x, y: x+y)\n",
        "  topWords = allCounts.top(20000, lambda x: x[1])\n",
        "  topWordsK = sc.parallelize(range(20000))\n",
        "  dictionary = topWordsK.map (lambda x : (topWords[x][0], x))\n",
        "  allWordsWithDocID = keyAndListOfWords.flatMap(lambda x: ((j, x[0]) for j in x[1]))\n",
        "  allDictionaryWords = allWordsWithDocID.join(dictionary)\n",
        "  justDocAndPos = allDictionaryWords.map(lambda x: x[1])\n",
        "  allDictionaryWordsInEachDoc = justDocAndPos.groupByKey()\n",
        "  allDocsAsNumpyArrays = allDictionaryWordsInEachDoc.map(lambda x: (x[0], buildArray(list(x[1]))))\n",
        "  xy = allDocsAsNumpyArrays.map(lambda x: (changeBinary(x[0]), x[1]))\n",
        "  xy1 = xy.map(lambda x: (x[0], x[1].tolist()))\n",
        "  xy_df = xy1.toDF([\"lab\", \"feat\"])\n",
        "  return (xy, xy_df)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SksHiSoB53PT",
        "outputId": "48d33eb1-a0a8-42b6-b901-3e9d43e48018"
      },
      "source": [
        "import timeit\n",
        "strt_total = timeit.default_timer()\n",
        "\n",
        "strt_read = timeit.default_timer()\n",
        "rd = sc.textFile(\"SmallTrainingData.txt\")\n",
        "stp_read = timeit.default_timer()\n",
        "print((stp_read - strt_read)/60, \"minutes to read the training data\")"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.0014213288333327985 minutes to read the training data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C9YGlhy457Qt"
      },
      "source": [
        "conv = conversion(rd)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GcTz8XTc58qM"
      },
      "source": [
        "df = conv[1]"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SVEv3Bf65-K0"
      },
      "source": [
        "from pyspark.ml.linalg import Vectors, VectorUDT\n",
        "from pyspark.sql.functions import udf"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "47teKGNk6CGE"
      },
      "source": [
        "convers = udf(lambda x: Vectors.dense(x), VectorUDT())\n",
        "df1 = df.withColumn(\"features\", convers(\"feat\")).drop(\"feat\")"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1nyoMxN26Ew8"
      },
      "source": [
        "from pyspark.ml.feature import ChiSqSelector\n",
        "selector=ChiSqSelector(numTopFeatures =10000, percentile=0.9, featuresCol=\"features\", outputCol='selectedFeatures', labelCol= 'lab')"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ierYgPh6hmw"
      },
      "source": [
        "model = selector.fit(df1)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yvKio8IP6jdO"
      },
      "source": [
        "res = model.transform(df1)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BoLf4ac46k6V"
      },
      "source": [
        "select_df = res.select('lab', 'selectedFeatures')"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gekwRxfF7h-4"
      },
      "source": [
        "from pyspark.ml.classification import LogisticRegression\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "from pyspark.ml.classification import LinearSVC"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wlRDKxPu6mij",
        "outputId": "1a7e44b6-1a20-4d39-9e5b-f12ef149cac3"
      },
      "source": [
        "lr_train_strt = timeit.default_timer()\n",
        "lr_red = LogisticRegression(featuresCol=\"selectedFeatures\", labelCol='lab',\n",
        "                        maxIter = 20)\n",
        "lrmodel_new = lr_red.fit(select_df)\n",
        "\n",
        "lr_train_stp = timeit.default_timer()\n",
        "print((lr_train_stp-lr_train_strt)/60, \"minutes to train the logistic regression with reduced features\")"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3.79750204705 minutes to train the logistic regression with reduced features\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X_W2Oz7T84xp",
        "outputId": "8e7d1ba6-85c3-4c21-f216-f1d4a0efb2d8"
      },
      "source": [
        "strt_read_test = timeit.default_timer()\n",
        "rd1 = sc.textFile(\"SmallTrainingData.txt\")\n",
        "stp_read_test = timeit.default_timer()\n",
        "print((stp_read_test - strt_read_test)/60, \"minutes to read the testing data\")"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.0010036462166662355 minutes to read the testing data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x833q4iM85Dr"
      },
      "source": [
        "conv1 = conversion(rd1)"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RklJ3T5O85HH"
      },
      "source": [
        "test_df = conv1[1]"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SusdVdX_8gvA"
      },
      "source": [
        "convers1 = udf(lambda x: Vectors.dense(x), VectorUDT())\n",
        "test_df1 = test_df.withColumn(\"features\", convers(\"feat\")).drop(\"feat\")"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ubxbSKVo9AzG"
      },
      "source": [
        "model1 = selector.fit(test_df1)"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QQOhgd_A9FA2"
      },
      "source": [
        "select_test_df = model.transform(test_df1).select('lab', 'selectedFeatures')"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vyHjlXCM92A2",
        "outputId": "b09092fb-8376-4974-a647-98c865e69d04"
      },
      "source": [
        "lr_test_strt = timeit.default_timer()\n",
        "lr_selected_pred = lrmodel_new.transform(select_test_df)\n",
        "\n",
        "multi_eval = MulticlassClassificationEvaluator(labelCol=\"lab\", metricName = \"accuracy\")\n",
        "print('Logistic Regression Accuracy on Selected Features:', multi_eval.evaluate(lr_selected_pred))\n",
        "\n",
        "multi_eval1 = MulticlassClassificationEvaluator(labelCol=\"lab\", metricName = \"f1\")\n",
        "print('Logistic Regression F1 on Selected Features:', multi_eval1.evaluate(lr_selected_pred))\n",
        "\n",
        "lr_test_stp = timeit.default_timer()\n",
        "\n",
        "lr_test_reduced = (lr_test_stp - lr_test_strt)/60\n",
        "print(lr_test_reduced, \"minutes to test the logistic regression with reduced features\")"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression Accuracy on Selected Features: 1.0\n",
            "Logistic Regression F1 on Selected Features: 1.0\n",
            "3.5288748549833335 minutes to test the logistic regression with reduced features\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "912fNRDB96cJ",
        "outputId": "530f8938-7356-40a9-9c95-9cfd213535f0"
      },
      "source": [
        "task3_total_stp = timeit.default_timer()\n",
        "total_logistic = (task3_total_stp - task3_total_strt)/60\n",
        "print(total_logistic, \"minutes total to complete the logistic regression\")"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "25.350520008233335 minutes total to complete the logistic regression\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ObQ123es-a_C",
        "outputId": "5b5e8f03-6c5f-448a-e29a-494c8ec89dea"
      },
      "source": [
        "svc_train_stp = timeit.default_timer()\n",
        "\n",
        "lsvc = LinearSVC(featuresCol=\"selectedFeatures\", labelCol='lab', maxIter=10, regParam=0.1)\n",
        "lsvcModel = lsvc.fit(select_df)\n",
        "\n",
        "svc_train_strt = timeit.default_timer()\n",
        "\n",
        "svc_train = (svc_train_strt - svc_train_stp)/60\n",
        "print(svc_train, \"minutes to train the support vector with reduced features\")"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3.683523200600003 minutes to train the support vector with reduced features\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BAB477rgAj3m",
        "outputId": "0df88046-0240-41e6-d743-bf6a632cc2ec"
      },
      "source": [
        "svc_test_stp = timeit.default_timer()\n",
        "\n",
        "svc_select_pred = lsvcModel.transform(select_df)\n",
        "\n",
        "multi_eval1 = MulticlassClassificationEvaluator(labelCol=\"lab\", metricName = \"accuracy\")\n",
        "print('SVC Accuracy on selected features:', multi_eval1.evaluate(svc_select_pred))\n",
        "\n",
        "multi_eval_f1 = MulticlassClassificationEvaluator(labelCol=\"lab\", metricName = \"f1\")\n",
        "print('SVC F1 on selected features:', multi_eval1.evaluate(svc_select_pred))\n",
        "\n",
        "svc_test_strt = timeit.default_timer()\n",
        "svc_test = (svc_test_strt - svc_test_stp)/60\n",
        "print(svc_test, \"minutes to test the support vector with reduced features\")"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SVC Accuracy on selected features: 1.0\n",
            "SVC F1 on selected features: 1.0\n",
            "3.548390619966661 minutes to test the support vector with reduced features\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IfLBFTtiBdcV",
        "outputId": "28c8663d-ce45-429e-df64-cc1df4bbfd0a"
      },
      "source": [
        "end_time = timeit.default_timer()\n",
        "total_time = (end_time - task3_total_strt)/60\n",
        "\n",
        "print(total_time - (lr_train_stp-lr_train_strt)/60 - lr_test_reduced, \"minutes total to complete SVC with reduced feature\")"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "27.883456125916666\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y3RuTzd9CWM_"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aO6SlnPBEax6"
      },
      "source": [
        ""
      ]
    }
  ]
}